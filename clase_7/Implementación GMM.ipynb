{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e510a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use black formatter\n",
    "# %load_ext lab_black\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caff8da",
   "metadata": {},
   "source": [
    "#### Generar un Dataset Sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418fbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(object):\n",
    "    def __init__(self, mu, var, p, n_samples):\n",
    "\n",
    "        n_uniform = np.random.uniform(0, 1, n_samples)\n",
    "        x = np.zeros(n_uniform.shape)\n",
    "        y = np.zeros(n_uniform.shape)\n",
    "\n",
    "        x[n_uniform <= p] = np.random.normal(mu[0], var[0], x[n_uniform <= p].shape[0])\n",
    "        x[n_uniform > p] = np.random.normal(mu[1], var[1], x[n_uniform > p].shape[0])\n",
    "        y[n_uniform <= p] = 0\n",
    "        y[n_uniform > p] = 1\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mu = mu\n",
    "        self.var = var\n",
    "\n",
    "    def split(self, percentage):  # 0.8\n",
    "\n",
    "        X = self.x\n",
    "        y = self.y\n",
    "\n",
    "        permuted_idxs = np.random.permutation(X.shape[0])\n",
    "        train_idxs = permuted_idxs[0 : int(percentage * X.shape[0])]\n",
    "        test_idxs = permuted_idxs[int(percentage * X.shape[0]) : X.shape[0]]\n",
    "\n",
    "        X_train = X[train_idxs]\n",
    "        X_test = X[test_idxs]\n",
    "\n",
    "        y_train = y[train_idxs]\n",
    "        y_test = y[test_idxs]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0318e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el dataset\n",
    "\n",
    "# Establecemos los parámetros de las GMM\n",
    "mu = np.array([5, 10])\n",
    "var = np.array([15, 2])\n",
    "p = 0.25\n",
    "\n",
    "dataset = SyntheticDataset(mu, var, p, 500)\n",
    "x_train, x_test, y_train, y_test = dataset.split(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88741bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (400,)\n",
      "Test:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", x_train.shape)\n",
    "print(\"Test: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1036f9d",
   "metadata": {},
   "source": [
    "#### Modelo de Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82892303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        return NotImplemented\n",
    "\n",
    "    def predict(self, X):\n",
    "        return NotImplemented\n",
    "\n",
    "\n",
    "class EMScalar(BaseModel):\n",
    "    def fit(self, X, k, n_iter=100):\n",
    "        # Los parámetros deben incluir al menos:\n",
    "        #  - Alguna forma de detener la iteración\n",
    "        #  - Los datos observados\n",
    "        #  - La cantidad de distribuciones\n",
    "\n",
    "        # Inicialización de parámetros\n",
    "        self.k = k\n",
    "        self.n_iter = n_iter\n",
    "        n = X.shape[0]\n",
    "\n",
    "        # Inicializar las probabilidades marginales de las clases P(z)\n",
    "        p = np.full((k, 1), 1 / k)\n",
    "\n",
    "        # Inicializar medias\n",
    "        means = np.random.uniform(min(X), max(X), (k, 1))\n",
    "\n",
    "        # Inicializar matrices covarianza\n",
    "        covs = np.sum((np.tile(X, (k, 1)) - means.reshape(-1, 1)) ** 2, axis=1) / (\n",
    "            n - 1\n",
    "        )\n",
    "\n",
    "        # Crear matrices place-holders para\n",
    "        # p(x|z) para cada clase z (n x k), [p(x1|z1) p(x1|z2) p(x1|z3) ..]\n",
    "        # Responsibilities\n",
    "        Nij = np.zeros((n, k))\n",
    "        Eij = np.zeros((n, k))\n",
    "\n",
    "        # Calcular, con los parámetros iniciales, p(x|z) para todos los z\n",
    "        for j in range(k):\n",
    "            Nij[:, j] = multivariate_normal.pdf(X, means[j], covs[j])\n",
    "\n",
    "        # Algoritmo de actualización\n",
    "        for _ in range(n_iter):\n",
    "            for j in range(k):\n",
    "                # Responsibilities\n",
    "                Eij[:, j] = (Nij[:, j] * p[j]) / (Nij @ p).reshape(-1)\n",
    "\n",
    "                # Actualizar medias\n",
    "                means[j] = (Eij[:, j] @ X) / np.sum(Eij[:, j])\n",
    "\n",
    "                # Actualizar covarianzas\n",
    "                covs[j] = (\n",
    "                    Eij[:, j] @ ((X - means[j]) * (X - means[j])) / np.sum(Eij[:, j])\n",
    "                )\n",
    "\n",
    "                # Actualizar pesos de clases\n",
    "                p[j] = np.sum(Eij[:, j]) / n\n",
    "\n",
    "                # Actualizar p(x|z)\n",
    "                Nij[:, j] = multivariate_normal.pdf(X, means[j], covs[j])\n",
    "\n",
    "        # Al finalizar el loop, guardar el modelo en la clase\n",
    "        self.model = {\n",
    "            \"means\": means,\n",
    "            \"covs\": covs,\n",
    "            \"p\": p,\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Devuelve para cada observación la clase asignada\n",
    "        n = X.shape[0]\n",
    "        k = self.model[\"means\"].shape[0]\n",
    "        N = np.zeros((n, k))\n",
    "        E = np.zeros((n, k))\n",
    "\n",
    "        for i in range(k):\n",
    "            N[:, i] = multivariate_normal.pdf(\n",
    "                X, self.model[\"means\"][i], self.model[\"covs\"][i]\n",
    "            )\n",
    "        for i in range(k):\n",
    "            E[:, i] = (self.model[\"p\"][i, 0] * N[:, i]) / (N @ self.model[\"p\"]).reshape(\n",
    "                -1\n",
    "            )\n",
    "        idx = np.argmax(E, axis=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f582e9",
   "metadata": {},
   "source": [
    "#### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37601ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_scalar = EMScalar()\n",
    "em_scalar.fit(x_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7bd29cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = em_scalar.predict(x_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db8d9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7c859",
   "metadata": {},
   "source": [
    "Como en este caso generamos un dataset sintético sabemos a que cluster pertenece cada punto. Gracias a esto podemos usar la métrica de accuracy para ver el porcentaje de aciertos de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c8cad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
